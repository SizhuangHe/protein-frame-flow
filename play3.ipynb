{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1546d3643700>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from models.together_model import ProteinVAELLMmodel\n",
    "from data import all_atom\n",
    "# Pytorch lightning imports\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from data.pdb_dataloader import PdbDataModule\n",
    "from models.flow_module import FlowModule\n",
    "from experiments import utils as eu\n",
    "import openfold.utils.rigid_utils as ru\n",
    "import torch.nn.functional as F\n",
    "cfg = OmegaConf.load(\"configs/base.yaml\")\n",
    "_cfg = cfg\n",
    "_data_cfg = cfg.data\n",
    "_exp_cfg = cfg.experiment\n",
    "_datamodule: LightningDataModule = PdbDataModule(_data_cfg)\n",
    "_datamodule.setup(stage=\"fit\")\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set stuff up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"configs/base.yaml\")\n",
    "_cfg = cfg\n",
    "_data_cfg = cfg.data\n",
    "_exp_cfg = cfg.experiment\n",
    "training_cfg = _exp_cfg.training\n",
    "_datamodule: LightningDataModule = PdbDataModule(_data_cfg)\n",
    "_datamodule.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = _datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.my_interpolant import Interpolant \n",
    "interpolant = Interpolant(cfg.interpolant)\n",
    "interpolant.set_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinVAELLMmodel(cfg).to(\"cuda\")\n",
    "model.attach_backward_hooks() # attach backward hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "            params=model.parameters(),\n",
    "            lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinVAELLMmodel(\n",
       "  (framediff_model): FlowModel(\n",
       "    (node_embedder): NodeEmbedder(\n",
       "      (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (edge_embedder): EdgeEmbedder(\n",
       "      (linear_s_p): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (linear_relpos): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (edge_embedder): Sequential(\n",
       "        (0): Linear(in_features=236, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (trunk): ModuleDict(\n",
       "      (ipa_0): InvariantPointAttention(\n",
       "        (linear_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (linear_kv): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (linear_q_points): Linear(in_features=128, out_features=192, bias=True)\n",
       "        (linear_kv_points): Linear(in_features=128, out_features=480, bias=True)\n",
       "        (linear_b): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (down_z): Linear(in_features=64, out_features=16, bias=True)\n",
       "        (linear_out): Linear(in_features=1536, out_features=128, bias=True)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (softplus): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (ipa_ln_0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq_tfmr_0): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_tfmr_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (node_transition_0): StructureModuleTransition(\n",
       "        (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear_3): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (bb_update_0): BackboneUpdate(\n",
       "        (linear): Linear(in_features=128, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vaellm_model): VAE_GPT2(\n",
       "    (llm_model): GPT2Model(\n",
       "      (wte): None\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (hid2mu): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (hid2sigma): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (lin_emb_backbone): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lin_deembed_backbone): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  1, 14, 13,  2, 10, 19,  9, 14, 13,  0, 19,  5, 11,  7,  6, 10, 16,\n",
      "          7,  6, 19,  1, 12, 14, 15,  7, 11, 16,  0,  1, 14,  2,  9, 16,  3,  2,\n",
      "         11,  3,  7, 16,  9, 16, 19,  1, 18,  0, 14, 16,  6, 11,  7, 10,  8,  5,\n",
      "         12,  7,  9, 11, 18,  3,  7,  2,  8,  9, 14,  7, 15, 14, 10,  5, 13, 18,\n",
      "         19,  3,  0,  9,  2, 15,  1,  8],\n",
      "        [ 6, 14, 19, 15, 11, 10,  1,  9,  1, 16, 14, 15,  7,  6, 13, 10,  6,  1,\n",
      "          1, 13, 10,  0, 15,  2, 11, 10,  5,  9, 19, 13,  3, 13, 19,  0, 15, 11,\n",
      "          7, 13, 14, 17,  3,  6, 18, 11, 10, 10, 15, 16, 13, 14,  1,  1,  3, 19,\n",
      "         16,  5, 10,  3, 14,  2, 11, 15, 10, 10,  6, 19, 11, 10, 13, 14,  5,  6,\n",
      "         16, 10, 13, 10,  6,  0, 11,  6],\n",
      "        [16,  6,  6,  5, 11,  1, 12, 10, 10, 10, 14,  0,  6,  0, 19,  2, 19, 15,\n",
      "          1, 11,  7,  6, 13, 16, 10, 11, 19,  7,  7, 15, 10, 11,  7,  0, 11,  2,\n",
      "         19, 18, 18,  2, 12,  0, 10, 12,  2,  0,  7, 19, 11, 11, 19, 19, 19,  1,\n",
      "         13,  3, 14,  5,  5, 10,  8, 15, 16, 19, 18,  4, 18, 16, 10,  3,  7,  1,\n",
      "         13,  9,  4,  6,  0,  6,  4, 10],\n",
      "        [15, 10, 16,  5,  6,  5, 10,  6,  3,  0,  1,  1, 10, 11,  0,  9, 17,  6,\n",
      "         11, 11, 11,  2,  6, 10,  7, 10, 15, 18,  6, 15, 19,  0,  3, 11, 12,  7,\n",
      "         12,  7,  5, 15,  0, 19,  0,  0, 10, 13,  2,  7,  9,  2,  0, 10,  2,  0,\n",
      "         18,  2,  0,  0, 10, 10,  0, 11,  9, 10, 11, 19, 15, 19,  6,  6, 13, 15,\n",
      "         14, 15,  9,  0,  1,  6,  9,  1],\n",
      "        [14, 12, 12,  1,  0, 12, 12, 12,  6, 13, 14,  3,  3, 14,  0,  4,  3, 18,\n",
      "         10,  3,  1,  5, 18, 12, 10,  7,  3,  2, 19, 12, 19,  0, 14, 19, 13, 16,\n",
      "          6,  0,  7,  3, 19,  5, 13, 18, 10, 14,  6,  7,  1, 17, 16,  8, 10, 17,\n",
      "          8,  2,  3,  6, 10,  3,  7, 15,  1, 17,  8, 11,  5,  5,  8,  7, 13, 10,\n",
      "         15, 10, 14, 19, 18, 19,  1,  3],\n",
      "        [ 8, 14,  9,  3,  8, 19,  7, 19,  5,  1, 10, 11,  2,  7, 10,  2,  0, 19,\n",
      "          7, 19,  0, 14,  9,  0,  7,  1, 19, 15,  7, 16,  9, 10, 16,  0, 19,  0,\n",
      "          3, 10, 12,  0,  1,  0,  7, 15,  3,  1,  9,  1, 13, 16, 14, 18,  5, 11,\n",
      "         10, 19,  9, 10,  3,  9, 14,  3,  0, 10, 10,  3,  3, 10,  9,  0,  7, 10,\n",
      "          3,  0, 10,  7, 10,  5, 15,  1],\n",
      "        [19, 19, 15,  4,  5,  5, 19,  6, 19,  6, 14, 10, 15,  0,  3,  3, 17,  6,\n",
      "          9, 10,  6, 10,  8,  0,  9, 15, 10,  6,  5,  8, 10, 10,  3,  5,  9,  1,\n",
      "          9, 19, 13, 14, 11,  0, 19, 19, 14,  9, 17, 19,  3,  5,  5, 16, 18,  9,\n",
      "         13,  9,  5,  9, 19, 16, 10, 12, 14,  0,  0, 14, 18,  7,  1, 10,  6, 16,\n",
      "          2, 16, 11, 10, 10,  9,  5, 14],\n",
      "        [ 3,  7,  7, 13,  4,  6, 19,  4, 11, 11, 10, 19,  7, 18, 10,  3,  1,  2,\n",
      "         10,  6, 11,  2, 15, 16, 11,  5,  6,  9, 10,  0,  0, 10,  6, 11,  7,  4,\n",
      "         15, 13, 10, 14,  3, 14, 18,  5, 11,  5,  4,  3,  5, 13, 19,  0,  6, 18,\n",
      "          6, 14, 19, 10,  9,  6,  9, 10, 19,  6, 19, 12,  3, 14, 15, 13, 19,  4,\n",
      "         10, 11,  9,  7,  0,  4, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch[\"aatype\"])\n",
    "for key, value in batch.items():\n",
    "    batch[key] = value.to(\"cuda\")\n",
    "noisy_batch = interpolant.corrupt_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with NaNs: []\n",
      "Parameters without NaNs: ['framediff_model.node_embedder.linear.weight', 'framediff_model.node_embedder.linear.bias', 'framediff_model.edge_embedder.linear_s_p.weight', 'framediff_model.edge_embedder.linear_s_p.bias', 'framediff_model.edge_embedder.linear_relpos.weight', 'framediff_model.edge_embedder.linear_relpos.bias', 'framediff_model.edge_embedder.edge_embedder.0.weight', 'framediff_model.edge_embedder.edge_embedder.0.bias', 'framediff_model.edge_embedder.edge_embedder.2.weight', 'framediff_model.edge_embedder.edge_embedder.2.bias', 'framediff_model.edge_embedder.edge_embedder.4.weight', 'framediff_model.edge_embedder.edge_embedder.4.bias', 'framediff_model.edge_embedder.edge_embedder.5.weight', 'framediff_model.edge_embedder.edge_embedder.5.bias', 'framediff_model.trunk.ipa_0.head_weights', 'framediff_model.trunk.ipa_0.linear_q.weight', 'framediff_model.trunk.ipa_0.linear_q.bias', 'framediff_model.trunk.ipa_0.linear_kv.weight', 'framediff_model.trunk.ipa_0.linear_kv.bias', 'framediff_model.trunk.ipa_0.linear_q_points.weight', 'framediff_model.trunk.ipa_0.linear_q_points.bias', 'framediff_model.trunk.ipa_0.linear_kv_points.weight', 'framediff_model.trunk.ipa_0.linear_kv_points.bias', 'framediff_model.trunk.ipa_0.linear_b.weight', 'framediff_model.trunk.ipa_0.linear_b.bias', 'framediff_model.trunk.ipa_0.down_z.weight', 'framediff_model.trunk.ipa_0.down_z.bias', 'framediff_model.trunk.ipa_0.linear_out.weight', 'framediff_model.trunk.ipa_0.linear_out.bias', 'framediff_model.trunk.ipa_ln_0.weight', 'framediff_model.trunk.ipa_ln_0.bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.self_attn.in_proj_weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.self_attn.in_proj_bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.self_attn.out_proj.weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.self_attn.out_proj.bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.linear1.weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.linear1.bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.linear2.weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.linear2.bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.norm1.weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.norm1.bias', 'framediff_model.trunk.seq_tfmr_0.layers.0.norm2.weight', 'framediff_model.trunk.seq_tfmr_0.layers.0.norm2.bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.self_attn.in_proj_weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.self_attn.in_proj_bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.self_attn.out_proj.weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.self_attn.out_proj.bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.linear1.weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.linear1.bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.linear2.weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.linear2.bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.norm1.weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.norm1.bias', 'framediff_model.trunk.seq_tfmr_0.layers.1.norm2.weight', 'framediff_model.trunk.seq_tfmr_0.layers.1.norm2.bias', 'framediff_model.trunk.post_tfmr_0.weight', 'framediff_model.trunk.post_tfmr_0.bias', 'framediff_model.trunk.node_transition_0.linear_1.weight', 'framediff_model.trunk.node_transition_0.linear_1.bias', 'framediff_model.trunk.node_transition_0.linear_2.weight', 'framediff_model.trunk.node_transition_0.linear_2.bias', 'framediff_model.trunk.node_transition_0.linear_3.weight', 'framediff_model.trunk.node_transition_0.linear_3.bias', 'framediff_model.trunk.node_transition_0.ln.weight', 'framediff_model.trunk.node_transition_0.ln.bias', 'framediff_model.trunk.bb_update_0.linear.weight', 'framediff_model.trunk.bb_update_0.linear.bias', 'vaellm_model.llm_model.wpe.weight', 'vaellm_model.llm_model.h.0.ln_1.weight', 'vaellm_model.llm_model.h.0.ln_1.bias', 'vaellm_model.llm_model.h.0.attn.c_attn.weight', 'vaellm_model.llm_model.h.0.attn.c_attn.bias', 'vaellm_model.llm_model.h.0.attn.c_proj.weight', 'vaellm_model.llm_model.h.0.attn.c_proj.bias', 'vaellm_model.llm_model.h.0.ln_2.weight', 'vaellm_model.llm_model.h.0.ln_2.bias', 'vaellm_model.llm_model.h.0.mlp.c_fc.weight', 'vaellm_model.llm_model.h.0.mlp.c_fc.bias', 'vaellm_model.llm_model.h.0.mlp.c_proj.weight', 'vaellm_model.llm_model.h.0.mlp.c_proj.bias', 'vaellm_model.llm_model.h.1.ln_1.weight', 'vaellm_model.llm_model.h.1.ln_1.bias', 'vaellm_model.llm_model.h.1.attn.c_attn.weight', 'vaellm_model.llm_model.h.1.attn.c_attn.bias', 'vaellm_model.llm_model.h.1.attn.c_proj.weight', 'vaellm_model.llm_model.h.1.attn.c_proj.bias', 'vaellm_model.llm_model.h.1.ln_2.weight', 'vaellm_model.llm_model.h.1.ln_2.bias', 'vaellm_model.llm_model.h.1.mlp.c_fc.weight', 'vaellm_model.llm_model.h.1.mlp.c_fc.bias', 'vaellm_model.llm_model.h.1.mlp.c_proj.weight', 'vaellm_model.llm_model.h.1.mlp.c_proj.bias', 'vaellm_model.llm_model.h.2.ln_1.weight', 'vaellm_model.llm_model.h.2.ln_1.bias', 'vaellm_model.llm_model.h.2.attn.c_attn.weight', 'vaellm_model.llm_model.h.2.attn.c_attn.bias', 'vaellm_model.llm_model.h.2.attn.c_proj.weight', 'vaellm_model.llm_model.h.2.attn.c_proj.bias', 'vaellm_model.llm_model.h.2.ln_2.weight', 'vaellm_model.llm_model.h.2.ln_2.bias', 'vaellm_model.llm_model.h.2.mlp.c_fc.weight', 'vaellm_model.llm_model.h.2.mlp.c_fc.bias', 'vaellm_model.llm_model.h.2.mlp.c_proj.weight', 'vaellm_model.llm_model.h.2.mlp.c_proj.bias', 'vaellm_model.llm_model.h.3.ln_1.weight', 'vaellm_model.llm_model.h.3.ln_1.bias', 'vaellm_model.llm_model.h.3.attn.c_attn.weight', 'vaellm_model.llm_model.h.3.attn.c_attn.bias', 'vaellm_model.llm_model.h.3.attn.c_proj.weight', 'vaellm_model.llm_model.h.3.attn.c_proj.bias', 'vaellm_model.llm_model.h.3.ln_2.weight', 'vaellm_model.llm_model.h.3.ln_2.bias', 'vaellm_model.llm_model.h.3.mlp.c_fc.weight', 'vaellm_model.llm_model.h.3.mlp.c_fc.bias', 'vaellm_model.llm_model.h.3.mlp.c_proj.weight', 'vaellm_model.llm_model.h.3.mlp.c_proj.bias', 'vaellm_model.llm_model.h.4.ln_1.weight', 'vaellm_model.llm_model.h.4.ln_1.bias', 'vaellm_model.llm_model.h.4.attn.c_attn.weight', 'vaellm_model.llm_model.h.4.attn.c_attn.bias', 'vaellm_model.llm_model.h.4.attn.c_proj.weight', 'vaellm_model.llm_model.h.4.attn.c_proj.bias', 'vaellm_model.llm_model.h.4.ln_2.weight', 'vaellm_model.llm_model.h.4.ln_2.bias', 'vaellm_model.llm_model.h.4.mlp.c_fc.weight', 'vaellm_model.llm_model.h.4.mlp.c_fc.bias', 'vaellm_model.llm_model.h.4.mlp.c_proj.weight', 'vaellm_model.llm_model.h.4.mlp.c_proj.bias', 'vaellm_model.llm_model.h.5.ln_1.weight', 'vaellm_model.llm_model.h.5.ln_1.bias', 'vaellm_model.llm_model.h.5.attn.c_attn.weight', 'vaellm_model.llm_model.h.5.attn.c_attn.bias', 'vaellm_model.llm_model.h.5.attn.c_proj.weight', 'vaellm_model.llm_model.h.5.attn.c_proj.bias', 'vaellm_model.llm_model.h.5.ln_2.weight', 'vaellm_model.llm_model.h.5.ln_2.bias', 'vaellm_model.llm_model.h.5.mlp.c_fc.weight', 'vaellm_model.llm_model.h.5.mlp.c_fc.bias', 'vaellm_model.llm_model.h.5.mlp.c_proj.weight', 'vaellm_model.llm_model.h.5.mlp.c_proj.bias', 'vaellm_model.llm_model.h.6.ln_1.weight', 'vaellm_model.llm_model.h.6.ln_1.bias', 'vaellm_model.llm_model.h.6.attn.c_attn.weight', 'vaellm_model.llm_model.h.6.attn.c_attn.bias', 'vaellm_model.llm_model.h.6.attn.c_proj.weight', 'vaellm_model.llm_model.h.6.attn.c_proj.bias', 'vaellm_model.llm_model.h.6.ln_2.weight', 'vaellm_model.llm_model.h.6.ln_2.bias', 'vaellm_model.llm_model.h.6.mlp.c_fc.weight', 'vaellm_model.llm_model.h.6.mlp.c_fc.bias', 'vaellm_model.llm_model.h.6.mlp.c_proj.weight', 'vaellm_model.llm_model.h.6.mlp.c_proj.bias', 'vaellm_model.llm_model.h.7.ln_1.weight', 'vaellm_model.llm_model.h.7.ln_1.bias', 'vaellm_model.llm_model.h.7.attn.c_attn.weight', 'vaellm_model.llm_model.h.7.attn.c_attn.bias', 'vaellm_model.llm_model.h.7.attn.c_proj.weight', 'vaellm_model.llm_model.h.7.attn.c_proj.bias', 'vaellm_model.llm_model.h.7.ln_2.weight', 'vaellm_model.llm_model.h.7.ln_2.bias', 'vaellm_model.llm_model.h.7.mlp.c_fc.weight', 'vaellm_model.llm_model.h.7.mlp.c_fc.bias', 'vaellm_model.llm_model.h.7.mlp.c_proj.weight', 'vaellm_model.llm_model.h.7.mlp.c_proj.bias', 'vaellm_model.llm_model.h.8.ln_1.weight', 'vaellm_model.llm_model.h.8.ln_1.bias', 'vaellm_model.llm_model.h.8.attn.c_attn.weight', 'vaellm_model.llm_model.h.8.attn.c_attn.bias', 'vaellm_model.llm_model.h.8.attn.c_proj.weight', 'vaellm_model.llm_model.h.8.attn.c_proj.bias', 'vaellm_model.llm_model.h.8.ln_2.weight', 'vaellm_model.llm_model.h.8.ln_2.bias', 'vaellm_model.llm_model.h.8.mlp.c_fc.weight', 'vaellm_model.llm_model.h.8.mlp.c_fc.bias', 'vaellm_model.llm_model.h.8.mlp.c_proj.weight', 'vaellm_model.llm_model.h.8.mlp.c_proj.bias', 'vaellm_model.llm_model.h.9.ln_1.weight', 'vaellm_model.llm_model.h.9.ln_1.bias', 'vaellm_model.llm_model.h.9.attn.c_attn.weight', 'vaellm_model.llm_model.h.9.attn.c_attn.bias', 'vaellm_model.llm_model.h.9.attn.c_proj.weight', 'vaellm_model.llm_model.h.9.attn.c_proj.bias', 'vaellm_model.llm_model.h.9.ln_2.weight', 'vaellm_model.llm_model.h.9.ln_2.bias', 'vaellm_model.llm_model.h.9.mlp.c_fc.weight', 'vaellm_model.llm_model.h.9.mlp.c_fc.bias', 'vaellm_model.llm_model.h.9.mlp.c_proj.weight', 'vaellm_model.llm_model.h.9.mlp.c_proj.bias', 'vaellm_model.llm_model.h.10.ln_1.weight', 'vaellm_model.llm_model.h.10.ln_1.bias', 'vaellm_model.llm_model.h.10.attn.c_attn.weight', 'vaellm_model.llm_model.h.10.attn.c_attn.bias', 'vaellm_model.llm_model.h.10.attn.c_proj.weight', 'vaellm_model.llm_model.h.10.attn.c_proj.bias', 'vaellm_model.llm_model.h.10.ln_2.weight', 'vaellm_model.llm_model.h.10.ln_2.bias', 'vaellm_model.llm_model.h.10.mlp.c_fc.weight', 'vaellm_model.llm_model.h.10.mlp.c_fc.bias', 'vaellm_model.llm_model.h.10.mlp.c_proj.weight', 'vaellm_model.llm_model.h.10.mlp.c_proj.bias', 'vaellm_model.llm_model.h.11.ln_1.weight', 'vaellm_model.llm_model.h.11.ln_1.bias', 'vaellm_model.llm_model.h.11.attn.c_attn.weight', 'vaellm_model.llm_model.h.11.attn.c_attn.bias', 'vaellm_model.llm_model.h.11.attn.c_proj.weight', 'vaellm_model.llm_model.h.11.attn.c_proj.bias', 'vaellm_model.llm_model.h.11.ln_2.weight', 'vaellm_model.llm_model.h.11.ln_2.bias', 'vaellm_model.llm_model.h.11.mlp.c_fc.weight', 'vaellm_model.llm_model.h.11.mlp.c_fc.bias', 'vaellm_model.llm_model.h.11.mlp.c_proj.weight', 'vaellm_model.llm_model.h.11.mlp.c_proj.bias', 'vaellm_model.llm_model.ln_f.weight', 'vaellm_model.llm_model.ln_f.bias', 'vaellm_model.hid2mu.weight', 'vaellm_model.hid2mu.bias', 'vaellm_model.hid2sigma.weight', 'vaellm_model.hid2sigma.bias', 'lin_emb_backbone.weight', 'lin_emb_backbone.bias', 'lin_deembed_backbone.weight', 'lin_deembed_backbone.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/nn/modules/module.py:1554: UserWarning: For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received <class 'transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions'>\n",
      "  warnings.warn(\"For backward hooks to be called,\"\n",
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/nn/modules/module.py:1554: UserWarning: For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received <class 'dict'>\n",
      "  warnings.warn(\"For backward hooks to be called,\"\n"
     ]
    }
   ],
   "source": [
    "B, l, num_res = noisy_batch['res_mask'].shape\n",
    "loss_mask = noisy_batch['res_mask'].reshape(B*l, num_res)\n",
    "        \n",
    "if training_cfg.min_plddt_mask is not None:\n",
    "    plddt_mask = noisy_batch['res_plddt'] > training_cfg.min_plddt_mask\n",
    "    loss_mask *= plddt_mask\n",
    "        \n",
    "\n",
    "# Ground truth labels\n",
    "gt_trans = noisy_batch['trans_t']\n",
    "gt_rotmats = noisy_batch['rotmats_t'] \n",
    "\n",
    "# Model output predictions.\n",
    "\n",
    "framediff_out = model(noisy_batch)\n",
    "pred_trans = framediff_out[\"pred_T\"]['pred_trans'].reshape(B, l, 128, 3)\n",
    "pred_rotmats = framediff_out[\"pred_T\"]['pred_rotmats'].reshape(B, l, 128, 3, 3)\n",
    "        \n",
    "# Shift for CausalLM\n",
    "shifted_pred_trans  = pred_trans[:, :-1, :, :]\n",
    "shifted_pred_rotmats = pred_rotmats[:, :-1, :, :, :]\n",
    "shifted_gt_trans = gt_trans[:, 1:, :, :]\n",
    "shifted_gt_rotmats = gt_rotmats[:, 1:, :, :, :]\n",
    "\n",
    "# Reshape back to [B*(l-1), 128, *]\n",
    "flat_shifted_pred_trans = shifted_pred_trans.reshape(B*(l-1), _data_cfg.dataset.max_num_res, 3)\n",
    "flat_shifted_pred_rotmats = shifted_pred_rotmats.reshape(B*(l-1), _data_cfg.dataset.max_num_res, 3, 3)\n",
    "\n",
    "flat_shifted_gt_trans = shifted_gt_trans.reshape(B*(l-1), _data_cfg.dataset.max_num_res, 3)\n",
    "flat_shifted_gt_rotmats = shifted_gt_rotmats.reshape(B*(l-1), _data_cfg.dataset.max_num_res, 3, 3)\n",
    "\n",
    "# Timestep used for normalization.\n",
    "t = noisy_batch['t'].reshape(B, l, 1)[:, 1:, :].reshape(-1,1) # We throw away the first time points\n",
    "norm_scale = 1 - torch.min(\n",
    "    t[..., None], torch.tensor(training_cfg.t_normalize_clip))\n",
    "        \n",
    "        \n",
    "\n",
    "# Backbone atom loss\n",
    "gt_bb_atoms = all_atom.to_atom37(flat_shifted_gt_trans, flat_shifted_gt_rotmats)[:, :, :3] \n",
    "pred_bb_atoms = all_atom.to_atom37(flat_shifted_pred_trans, flat_shifted_pred_rotmats)[:, :, :3]\n",
    "\n",
    "gt_bb_atoms *= training_cfg.bb_atom_scale / norm_scale[..., None]\n",
    "pred_bb_atoms *= training_cfg.bb_atom_scale / norm_scale[..., None]\n",
    "                \n",
    "        \n",
    "loss_denom = torch.sum(loss_mask, dim=-1, dtype=torch.float).mean() * 3 # Added a mean here, this doesn'y matter since our mask is all 1's\n",
    "bb_atom_loss = torch.sum(\n",
    "    (gt_bb_atoms - pred_bb_atoms) ** 2,\n",
    "    dim=(-1, -2, -3)\n",
    ") / loss_denom\n",
    "\n",
    "# Pairwise distance loss\n",
    "num_batch = gt_bb_atoms.shape[0]\n",
    "gt_flat_atoms = gt_bb_atoms.reshape([num_batch, num_res*3, 3])\n",
    "gt_pair_dists = torch.linalg.norm(\n",
    "    gt_flat_atoms[:, :, None, :] - gt_flat_atoms[:, None, :, :], dim=-1)\n",
    "pred_flat_atoms = pred_bb_atoms.reshape([num_batch, num_res*3, 3])\n",
    "pred_pair_dists = torch.linalg.norm(\n",
    "    pred_flat_atoms[:, :, None, :] - pred_flat_atoms[:, None, :, :], dim=-1)\n",
    "\n",
    "flat_loss_mask = torch.tile(loss_mask[:, :, None], (1, 1, 3))[B:,:,:] # change the shape because we shifted tokens, all entries of loss masks are 1 so don't matter, we throw away B tokens\n",
    "flat_loss_mask = flat_loss_mask.reshape([num_batch, num_res*3])\n",
    "flat_res_mask = torch.tile(loss_mask[:, :, None], (1, 1, 3))[B:,:,:] # change the shape because we shifted tokens, all entries of loss masks are 1 so don't matter\n",
    "flat_res_mask = flat_res_mask.reshape([num_batch, num_res*3])\n",
    "\n",
    "gt_pair_dists = gt_pair_dists * flat_loss_mask[..., None]\n",
    "pred_pair_dists = pred_pair_dists * flat_loss_mask[..., None]\n",
    "pair_dist_mask = flat_loss_mask[..., None] * flat_res_mask[:, None, :]\n",
    "\n",
    "dist_mat_loss = torch.sum(\n",
    "    (gt_pair_dists - pred_pair_dists)**2 * pair_dist_mask,\n",
    "    dim=(1, 2))\n",
    "dist_mat_loss /= (torch.sum(pair_dist_mask, dim=(1, 2)) - num_res)\n",
    "\n",
    "auxiliary_loss = (bb_atom_loss + dist_mat_loss) * (\n",
    "    t[:, 0]> training_cfg.aux_loss_t_pass\n",
    ")\n",
    "auxiliary_loss *= _exp_cfg.training.aux_loss_weight\n",
    "        \n",
    "auxiliary_loss = auxiliary_loss.mean()\n",
    "kl_div = (1 + 2 * framediff_out[\"vae_log_sigma\"] - framediff_out[\"vae_mu\"].pow(2) - framediff_out[\"vae_log_sigma\"].exp().pow(2))[:, :-1, :] # Throw away the last mu and sigma because we're not using it to predict\n",
    "kl_div = - 0.5 * kl_div.sum(dim=-1).mean()\n",
    "mse_loss = F.mse_loss(flat_shifted_pred_trans, flat_shifted_gt_trans) + F.mse_loss(flat_shifted_pred_rotmats, flat_shifted_gt_rotmats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48640104., device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Error detected in LinalgEighBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/tmp.dxbfOluFlz/ipykernel_324596/637163545.py\", line 15, in <module>\n",
      "    framediff_out = model(noisy_batch)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/models/together_model.py\", line 116, in forward\n",
      "    framediff_out = self.framediff_model(noisy_batch)\n",
      "  File \"/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/models/dev_flow_model.py\", line 107, in forward\n",
      "    curr_rigids = curr_rigids.compose_q_update_vec(\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/openfold/utils/rigid_utils.py\", line 1055, in compose_q_update_vec\n",
      "    new_rots = self._rots.compose_q_update_vec(\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/openfold/utils/rigid_utils.py\", line 607, in compose_q_update_vec\n",
      "    quats = self.get_quats()\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/openfold/utils/rigid_utils.py\", line 538, in get_quats\n",
      "    quats = rot_to_quat(self._rot_mats)\n",
      "  File \"/vast/palmer/home.mccleary/sh2748/protein-frame-flow/openfold/utils/rigid_utils.py\", line 226, in rot_to_quat\n",
      "    _, vectors = torch.linalg.eigh(k)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'LinalgEighBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'LinalgEighBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "loss = mse_loss + auxiliary_loss + kl_div\n",
    "print(loss)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit ('fm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0e2400c1a377b47623d27da16e17b3eddff11c79be96fbe43a1e38910d94694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
