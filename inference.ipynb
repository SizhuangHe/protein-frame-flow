{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/sh2748/conda_envs/fm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x153182d0f880>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from models.together_model import ProteinVAELLMmodel, ProteinVAELLM_FrameDiff_first_model\n",
    "from data import all_atom\n",
    "# Pytorch lightning imports\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from data.pdb_dataloader import PdbDataModule\n",
    "from models.flow_module import FlowModule\n",
    "from experiments import utils as eu\n",
    "from data import utils as du\n",
    "from analysis import metrics\n",
    "import openfold.utils.rigid_utils as ru\n",
    "import torch.nn.functional as F\n",
    "import subprocess\n",
    "from biotite.sequence.io import fasta\n",
    "cfg = OmegaConf.load(\"configs/base.yaml\")\n",
    "_cfg = cfg\n",
    "_data_cfg = cfg.data\n",
    "_exp_cfg = cfg.experiment\n",
    "_datamodule: LightningDataModule = PdbDataModule(_data_cfg)\n",
    "_datamodule.setup(stage=\"fit\")\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "pdb_path = \"/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0/sample.pdb\"\n",
    "sc_output_dir = os.path.join(\"/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0\", 'self_consistency')\n",
    "os.makedirs(sc_output_dir, exist_ok=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sample.pdb',\n",
       " '/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0/self_consistency/sample.pdb')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(pdb_path), os.path.join(sc_output_dir, os.path.basename(pdb_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0/self_consistency/sample.pdb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(pdb_path, os.path.join(sc_output_dir, os.path.basename(pdb_path)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-07 14:04:46,452] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/sh2748/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-devel package with yum\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld.gold: error: cannot find -laio\n",
      "/tmp/tmp.ZHabli45NE/tmpjr_l5e7_/test.o:test.c:function main: error: undefined reference to 'io_pgetevents'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "import esm\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "_pmpnn_dir = \"./ProteinMPNN/\"\n",
    "seq_per_sample = 8\n",
    "gpu_id = None\n",
    "_folding_model = esm.pretrained.esmfold_v1().eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self_consistency(\n",
    "        decoy_pdb_dir: str,\n",
    "        reference_pdb_path: str,\n",
    "        motif_mask: Optional[np.ndarray]=None):\n",
    "    \"\"\"Run self-consistency on design proteins against reference protein.\n",
    "        \n",
    "        Args:\n",
    "            decoy_pdb_dir: directory where designed protein files are stored.\n",
    "            reference_pdb_path: path to reference protein file\n",
    "            motif_mask: Optional mask of which residues are the motif.\n",
    "\n",
    "        Returns:\n",
    "            Writes ProteinMPNN outputs to decoy_pdb_dir/seqs\n",
    "            Writes ESMFold outputs to decoy_pdb_dir/esmf\n",
    "            Writes results in decoy_pdb_dir/sc_results.csv\n",
    "    \"\"\"\n",
    "\n",
    "    # Run PorteinMPNN\n",
    "    output_path = os.path.join(decoy_pdb_dir, \"parsed_pdbs.jsonl\")\n",
    "    process = subprocess.Popen([\n",
    "        'python',\n",
    "        f'{_pmpnn_dir}/helper_scripts/parse_multiple_chains.py',\n",
    "        f'--input_path={decoy_pdb_dir}',\n",
    "        f'--output_path={output_path}',\n",
    "    ])\n",
    "    _ = process.wait()\n",
    "\n",
    "    num_tries = 0\n",
    "    ret = -1\n",
    "    pmpnn_args = [\n",
    "        'python',\n",
    "        f'{_pmpnn_dir}/protein_mpnn_run.py',\n",
    "        '--out_folder',\n",
    "        decoy_pdb_dir,\n",
    "        '--jsonl_path',\n",
    "        output_path,\n",
    "        '--num_seq_per_target',\n",
    "        str(seq_per_sample),\n",
    "        '--sampling_temp',\n",
    "        '0.1',\n",
    "        '--seed',\n",
    "        '38',\n",
    "        '--batch_size',\n",
    "        '1',\n",
    "    ]\n",
    "    if gpu_id is not None:\n",
    "        pmpnn_args.append('--device')\n",
    "        pmpnn_args.append(str(gpu_id))\n",
    "    while ret < 0:\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                pmpnn_args,\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "            ret = process.wait()\n",
    "        except Exception as e:\n",
    "            num_tries += 1\n",
    "            print(f'Failed ProteinMPNN. Attempt {num_tries}/5')\n",
    "            torch.cuda.empty_cache()\n",
    "            if num_tries > 4:\n",
    "                raise e\n",
    "    print(f\"Return value: {ret}\")\n",
    "    mpnn_fasta_path = os.path.join(\n",
    "        decoy_pdb_dir,\n",
    "        'seqs',\n",
    "        os.path.basename(reference_pdb_path).replace('.pdb', '.fa')\n",
    "    )\n",
    "    print(mpnn_fasta_path)\n",
    "    # Run ESMFold on each ProteinMPNN sequence and calculate metrics.\n",
    "    mpnn_results = {\n",
    "        'tm_score': [],\n",
    "        'sample_path': [],\n",
    "        'header': [],\n",
    "        'sequence': [],\n",
    "        'rmsd': [],\n",
    "    }\n",
    "    if motif_mask is not None:\n",
    "        # Only calculate motif RMSD if mask is specified.\n",
    "        mpnn_results['motif_rmsd'] = []\n",
    "    esmf_dir = os.path.join(decoy_pdb_dir, 'esmf')\n",
    "    os.makedirs(esmf_dir, exist_ok=True)\n",
    "    \n",
    "    fasta_seqs = fasta.FastaFile.read(mpnn_fasta_path)\n",
    "    sample_feats = du.parse_pdb_feats('sample', reference_pdb_path)\n",
    "    for i, (header, string) in enumerate(fasta_seqs.items()):\n",
    "\n",
    "        # Run ESMFold\n",
    "        esmf_sample_path = os.path.join(esmf_dir, f'sample_{i}.pdb')\n",
    "        _ = run_folding(string, esmf_sample_path)\n",
    "        esmf_feats = du.parse_pdb_feats('folded_sample', esmf_sample_path)\n",
    "        sample_seq = du.aatype_to_seq(sample_feats['aatype'])\n",
    "\n",
    "        # Calculate scTM of ESMFold outputs with reference protein\n",
    "        _, tm_score = metrics.calc_tm_score(\n",
    "            sample_feats['bb_positions'], esmf_feats['bb_positions'],\n",
    "            sample_seq, sample_seq)\n",
    "        rmsd = metrics.calc_aligned_rmsd(\n",
    "            sample_feats['bb_positions'], esmf_feats['bb_positions'])\n",
    "        if motif_mask is not None:\n",
    "            sample_motif = sample_feats['bb_positions'][motif_mask]\n",
    "            of_motif = esmf_feats['bb_positions'][motif_mask]\n",
    "            motif_rmsd = metrics.calc_aligned_rmsd(\n",
    "                sample_motif, of_motif)\n",
    "            mpnn_results['motif_rmsd'].append(motif_rmsd)\n",
    "        mpnn_results['rmsd'].append(rmsd)\n",
    "        mpnn_results['tm_score'].append(tm_score)\n",
    "        mpnn_results['sample_path'].append(esmf_sample_path)\n",
    "        mpnn_results['header'].append(header)\n",
    "        mpnn_results['sequence'].append(string)\n",
    "\n",
    "        # Save results to CSV\n",
    "    csv_path = os.path.join(decoy_pdb_dir, 'sc_results.csv')\n",
    "    mpnn_results = pd.DataFrame(mpnn_results)\n",
    "    mpnn_results.to_csv(csv_path)\n",
    "\n",
    "\n",
    "def run_folding(sequence, save_path):\n",
    "    \"\"\"Run ESMFold on sequence.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = _folding_model.infer_pdb(sequence)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0/self_consistency'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return value: 0\n",
      "/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06/length_100/sample_0/self_consistency/seqs/sample.fa\n"
     ]
    }
   ],
   "source": [
    "run_self_consistency(decoy_pdb_dir=sc_output_dir, reference_pdb_path=pdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as gg\n",
    "\n",
    "def read_samples(results_dir):\n",
    "    all_csvs = []\n",
    "    print(f'Reading samples from {results_dir}')\n",
    "    for sample_length in os.listdir(results_dir):\n",
    "        if '.' in sample_length:\n",
    "            continue\n",
    "        length_dir = os.path.join(results_dir, sample_length)\n",
    "        length = int(sample_length.split('_')[1])\n",
    "        for i,sample_name in enumerate(os.listdir(length_dir)):\n",
    "            if '.' in sample_name:\n",
    "                continue\n",
    "            csv_path = os.path.join(length_dir, sample_name, 'self_consistency', 'sc_results.csv')\n",
    "            if os.path.exists(csv_path):\n",
    "                design_csv = pd.read_csv(csv_path, index_col=0)\n",
    "                design_csv['length'] = length\n",
    "                design_csv['sample_id'] = i\n",
    "                all_csvs.append(design_csv)\n",
    "    results_df = pd.concat(all_csvs)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def sc_filter(raw_df, metric):\n",
    "    # Pick best self-consistency sample\n",
    "    if metric == 'tm_score':\n",
    "        df = raw_df.sort_values('tm_score', ascending=False)\n",
    "        df['designable'] = df.tm_score.map(lambda x: x > 0.5)\n",
    "    elif metric == 'rmsd':\n",
    "        df = raw_df.sort_values('rmsd', ascending=True)\n",
    "        df['designable'] = df.rmsd.map(lambda x: x < 2.0)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown metric {metric}')\n",
    "    df = df.groupby(['length', 'sample_id']).first().reset_index()\n",
    "    percent_designable = df['designable'].mean()\n",
    "    print(f'Percent designable: {percent_designable}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading samples from /home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06\n",
      "Percent designable: 0.0\n",
      "Percent designable: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples_df = read_samples(\"/home/sh2748/inference_outputs/baseline/2024-04-30_15-54-45/epoch=11-step=23628/run_2024-05-01_23-06\")\n",
    "samples_df = samples_df[samples_df.sample_id < 8] # Ensure we only consider 8 sequences per backbone.\n",
    "\n",
    "scrmsd_results = sc_filter(samples_df, 'rmsd')\n",
    "sctm_results = sc_filter(samples_df, 'tm_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit ('fm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0e2400c1a377b47623d27da16e17b3eddff11c79be96fbe43a1e38910d94694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
